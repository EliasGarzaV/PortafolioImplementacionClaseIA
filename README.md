# Repositorio de IMplementaciÃ³n y Machine Learning
Este es el repositorio de ImplementaciÃ³n para la concentraciÃ³n en Inteligencia Artificial Avanzada de ElÃ­as Garza ValdÃ©s A01284041.
## Entregables
- [Entregable 1: 21/08/2023](Entregables/Entregable1.ipynb) - Este es el notebook en donde esta la implementaciÃ³n manual de una regresion multilinear correspondiente para la etapa 1.

- [Entregable 2: 31/08/2023](Entregables/Entregable2.ipynb) - Este es el notebook en donde esta la implementaciÃ³n con framework de algun modelo visto en clase.

- [Entregable 3: 05/09/2023](Entregables/Entregable3.ipynb) - Aqui viene el analisis sobre el desempeÃ±o de los modelos. 

- [Entregable Final: 11/09/2023](Entregables/EntregableFinalML.ipynb) - Este es el resultado final con la concatenaciÃ³n de las entregas con todas las correcciones hechas para el mÃ³dulo de Machine learning. Contiene la aparte de implementaciÃ³n asi como la Ãºltima entrega de AnÃ¡lisis para las cuales se utilizÃ³ el mismo modelo. (*Si usted es el profesor Ivan este es el archivo bueno por ver*)

## Estructura del Repositorio 
```
ğŸ“¦PortafolioImplementacionClaseIA
 â”£ ğŸ“‚Actividades Estadistica
 â”ƒ â”£ ğŸ“œAct-4-Intervalos.pdf
 â”ƒ â”£ ğŸ“œAct-6ANOVAS.pdf
 â”ƒ â”£ ğŸ“œAct7.pdf
 â”ƒ â”— ğŸ“œActividad-5.pdf
 â”£ ğŸ“‚Data
 â”ƒ â”£ ğŸ“œdiabetes-dataset.csv
 â”ƒ â”— ğŸ“œsalary.csv
 â”£ ğŸ“‚Entregables
 â”ƒ â”£ ğŸ“œEntregable1.ipynb
 â”ƒ â”£ ğŸ“œEntregable2.ipynb
 â”ƒ â”£ ğŸ“œEntregable3.ipynb
 â”ƒ â”— ğŸ“œEntregableFinalML.ipynb
 â”£ ğŸ“‚functions
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œevaluation.cpython-39.pyc
 â”ƒ â”ƒ â”— ğŸ“œMultilinear_regression.cpython-39.pyc
 â”ƒ â”£ ğŸ“œevaluation.py
 â”ƒ â”— ğŸ“œMultilinear_regression.py
 â”— ğŸ“œREADME.md
```

## Sobre el problema y los datos

Tenemos un  problema de regresiÃ³n con datos de profesores en una universidad con los cuales vamos a intentar predecir su salario. Tenemos un rango de variables como lo son su puesto actual, la materia que imparten, la cantidad de aÃ±os desde que obtuvieron su doctorado, los aÃ±os que llevan trabajando y su sexo. Asimismo, tambien tenemos la columna del salario de profesores para hacer la prueba. Este dataset lo pueden encontrar en [Datos_Salariales](Data/salary.csv).

## Modelado

En cuanto al modelo utilizado tenemos varias pruebas. Inicialmente haremos una regresiÃ³n lineal tanto de la forma optima con mÃ­nimos cuadrados (el dataset no es muy grande asi que en este caso es la mejor opciÃ³n ya que tenemos suficiente memoria para los cÃ¡lculos) como a traves de un optimizador el cual intentarÃ¡ ir moviendo los valores de los coeficientes para llegar a un Ã³ptimo local.  

Posteriormente veremos que tal funciona otro modelo como arboles de regreciÃ³n o xgboost. 

## Sobre los cambios y correcciones


### ImplementaciÃ³n
Los siguientes son las correcciones que se le han aplicado a este documento a partir de la retroalimentaciÃ³n del profesor para el caso del portafolio de ImplementaciÃ³n:

 - AÃ±adir contexto sobre la base de datos y link en el `README.md` de este repositorio.
 - AÃ±adir descripciÃ³n del modelo utilizado en el `README:md`
 - El reporte ahora incluye la descripciÃ³n de los datos asi como el nombre. 
 - Tenemos ahora el reporte generado de exploraciÃ³n de datos. 
 - Al inicio del reporte tenemos la explicaciÃ³n de que es un problema de regresiÃ³n. 
 - Ahora se aÃ±ade los resultados del conjunto de entrenamiento ademÃ¡s del de pruebas.
 - El modelo ahora contiene pruebas ademas de las de entrenamiento (el testing al final)
 - Ahora se hace la comparaciÃ³n con residuales y la diferencia entre los resultados. 
 - Ahora se varian diversos hiperparÃ¡metros al momento de generar las pruebas. 

### AnÃ¡lisis
Asimismo, para la entrega de AnÃ¡lisis tenmos los siguientes cambios (excluyendo cambios redundantes que ya se hicieron para la parte de implementacion):

 - Ahora separamos los datos en entrenamiento-validaciÃ³n-pruebas en una proporciÃ³n 64:16:20. 
 - Hacemos todas nuestras pruebas con el conjunto de validaciÃ³n. El de pruebas es solo al final para revisar la evaluaciÃ³n final del modelo. 
 - Hacemos una busqueda para optimizar los hiperparÃ¡metros del modelo de gradiente descendiente estocastico. Variamos el learning rate inicial, el parametro de regularizaciÃ³n, la funciÃ³n de error y las iteraciones mÃ¡ximas. 
 - Analizamos el sesgo comparando las mÃ©tricas de nuestros 3 conjuntos de datos y tenemos la tabla de diferencias entre nuestros conjuntos de entrenamiento y validaciÃ³n para el caso del gradiente descendiente. 
 - La varianza ahora la podemos ver a travÃ©s de los diagramas de residuos de nuestros modelos los cuales se encuentran en la evaluaciÃ³n. 
 - Comparamos las metricas de los conjuntos para concluir que no tenemos un overfitting alto. 
 - En nuestro modelo de gradiente descendiente aÃ±adimos una regularizaciÃ³n del tipo 'l1' para mejorar los resultados. 
 

